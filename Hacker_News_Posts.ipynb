{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Hacker News Posts\n",
    "\n",
    "##### Objectives\n",
    "\n",
    "The project aims to answer the following questions from the data:\n",
    "\n",
    "1. Which post ('Ask HN' or 'Show HN' posts) receives more comments on average?\n",
    "2. Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "##### Data\n",
    "\n",
    "The data set can be found [here](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts). It has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not  receive any comments and then randomly sampling from the remaining submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall begin by opening and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "print(headers)\n",
    "print(hn[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall identify the number of posts that start with 'Ask HN', 'Show HN' and those that do not belong to either category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Posts: 1744\n",
      "Show Posts: 1162\n",
      "Other Posts: 17194\n"
     ]
    }
   ],
   "source": [
    "print('Ask Posts:', len(ask_posts))\n",
    "print('Show Posts:', len(show_posts))\n",
    "print('Other Posts:', len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, there are 1744 'Ask HN' posts as compared to 1162 'Show HN' posts.\n",
    "\n",
    "We shall proceed to calculate the average number of comments for each category of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ask_comments=0\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "    avg_ask_comments= total_ask_comments/(len(ask_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_show_comments=0\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "    avg_show_comments= total_show_comments/(len(show_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans to Q1: 'Ask HN' posts.\n",
    "\n",
    "The average number of comments received for 'Ask HN' posts (14) is higher than the average number of comments received for 'Show HN' posts (10.3).\n",
    "\n",
    "Moving forward, we will focus our remaining analysis on \"Ask HN' posts for Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall begin by creating a list consisting of the timing of posts and the numbers of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "result_list=[]\n",
    "for post in ask_posts:\n",
    "    result_list.append([post[6], int(post[4])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall create a dictionary to capture the number of posts on an hourly basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': 251,\n",
       " '13': 1253,\n",
       " '10': 793,\n",
       " '14': 1416,\n",
       " '16': 1814,\n",
       " '23': 543,\n",
       " '12': 687,\n",
       " '17': 1146,\n",
       " '15': 4477,\n",
       " '21': 1745,\n",
       " '20': 1722,\n",
       " '02': 1381,\n",
       " '18': 1439,\n",
       " '03': 421,\n",
       " '05': 464,\n",
       " '19': 1188,\n",
       " '01': 683,\n",
       " '22': 479,\n",
       " '08': 492,\n",
       " '04': 337,\n",
       " '00': 447,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '11': 641}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_by_hour={}\n",
    "comments_by_hour={}\n",
    "date_format= \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    if time in counts_by_hour:\n",
    "        comments_by_hour[time] += comment\n",
    "        counts_by_hour[time] += 1\n",
    "    else:\n",
    "        comments_by_hour[time] = comment\n",
    "        counts_by_hour[time] = 1\n",
    "\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall edit the dictionary to a list to capture the average number of posts on an hourly basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour=[]\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "    avg_by_hour.append([hr, comments_by_hour[hr] / counts_by_hour[hr]])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall swap the first and second elements in order to sort the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour=[]\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap=sorted(swap_avg_by_hour, reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments:\n",
      "15:00 : 38.59 average comments per post\n",
      "02:00 : 23.81 average comments per post\n",
      "20:00 : 21.52 average comments per post\n",
      "16:00 : 16.80 average comments per post\n",
      "21:00 : 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for 'Ask HN' Comments:\")\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{} : {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"), avg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans to Q2: The top 5 timings to receive the most posts on average are 15:00, 2:00, 20:00, 16:00 and 21:00."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
